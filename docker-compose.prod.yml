# Book A Meal API - Production Docker Compose
#
# Prerequisites:
#   1. Copy .env.example to .env.prod and fill in all values
#   2. Point your domain's DNS A record to this server's IP
#   3. Caddy handles TLS automatically via Let's Encrypt (ports 80 + 443 must be open)
#
# Start:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Run migrations manually (e.g. before first deploy or after schema changes):
#   docker-compose -f docker-compose.prod.yml run --rm api sh -c "yarn sequelize-cli:es6 db:migrate"
#
# Using an external database (Neon, Supabase, RDS, etc.):
#   Set DATABASE_URL in .env.prod to your external connection string,
#   then remove the 'postgres' service and its 'depends_on' from this file.

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.prod
    env_file:
      - .env.prod
    environment:
      - NODE_ENV=production
      - PORT=8000
    depends_on:
      postgres:
        condition: service_healthy
    restart: always
    # No ports exposed directly — Caddy is the only public-facing service

  caddy:
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./docker/Caddyfile.prod:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    env_file:
      - .env.prod
    depends_on:
      - api
    restart: always

  postgres:
    image: postgres:14-alpine
    environment:
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USERNAME} -d ${DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
    # Postgres is intentionally not exposed to the host — only accessible inside Docker network

volumes:
  postgres_data:
  caddy_data:
  caddy_config:
